{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vit\n",
    "import training_utils\n",
    "import dataset_utils\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config: vit.ViTConfig = {\n",
    "    'd_model': 256,\n",
    "    'num_heads': 8,\n",
    "    'num_layers': 12,\n",
    "    'd_ffn': 4*256,\n",
    "    'dropout': 0.2,\n",
    "    \n",
    "    'image_size': 32,\n",
    "    'image_channels': 3,\n",
    "    'patch_size': 4,\n",
    "    'out_classes': 10\n",
    "}\n",
    "\n",
    "train_config: training_utils.TrainConfig = {\n",
    "    'num_steps': 10_000,\n",
    "    'warmup_steps': 2_000,\n",
    "    'optimizer': {\n",
    "        'optim': \"SGD\",\n",
    "        'base_lr': 1,\n",
    "        'args': {\n",
    "        }\n",
    "    },\n",
    "    'batches_per_step': 1,\n",
    "    'eval_interval': 1000,\n",
    "    'log_interval': 100,\n",
    "    'autocast': True,\n",
    "    'lr_scheduler': \"like_transformer\",\n",
    "    'label_smoothing': 0.1  ,\n",
    "    'clip_grad': None\n",
    "}\n",
    "\n",
    "dataset_config: dataset_utils.DatasetConfig = {\n",
    "    'dataset': \"CIFAR10\",\n",
    "    'augmentation': \"AutoCIFAR10\",\n",
    "    'batch_size': 512,\n",
    "    'num_workers': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='vit-classifier', config={\n",
    "    'dataset': dataset_config,\n",
    "    'model': model_config,\n",
    "    'train': train_config\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit.get_model(model_config)\n",
    "optim = training_utils.get_optim(train_config, model)\n",
    "lr_scheduler = training_utils.get_scheduler(train_config, optim, d_model=model_config['d_model'])\n",
    "train_loader, test_loader = dataset_utils.get_dataloader(dataset_config, 'data')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=train_config['label_smoothing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_loss(model, batch: list[torch.Tensor]) -> torch.Tensor:\n",
    "    model.train()\n",
    "    img, label = batch\n",
    "    img, label = img.to(device), label.to(device)\n",
    "    img = vit.image_to_patches(img, model_config['patch_size'])\n",
    "    \n",
    "    pred = model(img)\n",
    "    loss = criterion(pred, label)\n",
    "    return loss\n",
    "\n",
    "def eval_model(model) -> float:\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for input, target in test_loader:\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            input = vit.image_to_patches(input, model_config['patch_size'])\n",
    "\n",
    "            predicted = model.predict(input)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    training_utils.train(\n",
    "        model,\n",
    "        train_config,\n",
    "        optim,\n",
    "        lr_scheduler,\n",
    "        calc_train_loss,\n",
    "        train_loader,\n",
    "        eval_model,\n",
    "        device\n",
    "    )\n",
    "finally:\n",
    "    try:\n",
    "        torch.save(model.state_dict(), 'models/cifar10.pt')\n",
    "        wandb.log_model(path='models/cifar10.pt', name='cifar10or100')\n",
    "        wandb.finish()\n",
    "    finally:\n",
    "        import os\n",
    "        os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
